{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put a slow control information in run database for processing\n",
    "\n",
    "_2016 June 15th: Made by Christopher Tunnell_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting routines that sets figure sizes and says\n",
    "# to make plots inline this notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rc('font', size=16)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0) # resize plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scientific python stack\n",
    "import numpy as np  # numerical package\n",
    "import pandas as pd # analytics package\n",
    "from scipy.optimize import curve_fit # Fitting routines\n",
    "from scipy import stats  # Statistics routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/anaconda3/envs/pax/lib/python3.4/site-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import hax routines to help access data\n",
    "import hax\n",
    "from hax.runs import update_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "version = '5.0.0'\n",
    "hax.init(main_data_paths=['/project/lgrandi/xenon1t/processed/pax_v%s' % version],\n",
    "         minitree_paths=['minitrees_v%s' % version],pax_version_policy = 'loose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from hax import slow_control\n",
    "\n",
    "class SlowControlCryogenics(hax.minitrees.TreeMaker):\n",
    "    # Activate the required branch while reading in the ROOT file\n",
    "    # If you're too lazy to specify this, just put '*', but your TreeMaker will run slow!\n",
    "    extra_branches = []\n",
    "    __version__ = '0.0.1'\n",
    "    \n",
    "    def __init__(self):\n",
    "        variables = slow_control.VARIABLES['cryogenics']\n",
    "        self.df = {}\n",
    "        for short_name, variable in variables.items():\n",
    "            self.df[short_name] = slow_control.get_series(variable, None)\n",
    "        self.df = pd.DataFrame(self.df)\n",
    "\n",
    "        hax.minitrees.TreeMaker.__init__(self)\n",
    "    \n",
    "    def extract_data(self, event):\n",
    "        x = event.start_time\n",
    "        x = int(x * 1e-9) # seconds\n",
    "        x = datetime.datetime.utcfromtimestamp(int(x))\n",
    "        #print(series.between_time(x, x+ datetime.timedelta(minutes=10)))\n",
    "        #print(series.find(x))\n",
    "        \n",
    "        i = self.df.index.searchsorted(x)\n",
    "        return self.df.iloc[i].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot find processed data for run name 160625_1438.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a28e52fd568c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_tpc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminitrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1095\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtreemakers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSlowControlCryogenics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Basics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/erik/hax/hax/minitrees.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(datasets, treemakers, force_reload)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mdataframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mminitree_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtreemaker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_reload\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m             \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_numpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot2rec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminitree_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mdataframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/erik/hax/hax/minitrees.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(run_name, treemaker, force_reload)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# We have to make the minitree file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# This will raise FileNotFoundError if the root file is not found\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mskimmed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreemaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created minitree %s for dataset %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtreemaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/erik/hax/hax/minitrees.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mruns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_run_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         loop_over_dataset(dataset, self.process_event,\n\u001b[1;32m---> 50\u001b[1;33m                           branch_selection=hax.config['basic_branches'] + list(self.extra_branches))\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_empty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/erik/hax/hax/paxroot.py\u001b[0m in \u001b[0;36mloop_over_datasets\u001b[1;34m(datasets_names, event_function, branch_selection)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbranches\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \"\"\"\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunction_results_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbranch_selection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;31m# do nothing with the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/erik/hax/hax/paxroot.py\u001b[0m in \u001b[0;36mfunction_results_datasets\u001b[1;34m(datasets_names, event_function, branch_selection, kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrun_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mrootfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_pax_rootfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;31m# If you get \"'TObject' object has no attribute 'GetEntries'\" here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# we renamed the tree to T1 or TPax or something... or you're trying to load a Xerawdp root file!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/erik/hax/hax/paxroot.py\u001b[0m in \u001b[0;36mopen_pax_rootfile\u001b[1;34m(run_id)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_file_in_folders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_id\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.root'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'main_data_paths'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot find processed data for run name %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_open_pax_rootfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot find processed data for run name 160625_1438."
     ]
    }
   ],
   "source": [
    "df_tpc = hax.minitrees.load(1095, treemakers=[SlowControlCryogenics, 'Basics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tpc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d604f5c9880b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_tpc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_tpc' is not defined"
     ]
    }
   ],
   "source": [
    "df_tpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
